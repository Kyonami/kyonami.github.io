# Chapter 2. 딥러닝

데이터 처리 유닛의 층을 여러 개 쌓아 구조화가 안된 데이터에서 높은 수준의 표현을 학습한다.

## 2.1 딥러닝용 데이터

대부분의 알고리즘은 테이블 형태로 된 정형(구조화 된) 데이터를 입력으로 사용한다.
이런 형태의 테이블 데이터를 사용해 로지스틱 회귀(랜덤 포레스트), XGBoost 모델을 훈련하여 이진 응답 변수 예측이 가능하다.

> 예를 들어 어떤 사람의 나이, 소득, 방문 횟수등을 통해 이 사람이 구독을 할지(1) 안 할지(0)를 나타낼 수 있다.

비정형 데이터 (구조화 되지 않은 데이터)는 이미지, 오디오, 텍스트 처럼 따로 열로 구성할 수 없는 데이터이다.

<img src="../../images/image-20251221143448173.png" alt="image-20251221143448173" style="zoom:50%;" />

픽셀, 징동수, 문자 하나하나엔 거의 정보가 없다. 234번째 픽셀의 색을 보고 무슨 이미지인지 알 수 없고, 24번째 문자가 e라는 사실로 축구에 관한 내용인지 정치에 관한 내용인지 알 수 없다.
그러므로 이런 원시 픽셀에서 로지스틱 회귀, 랜덤 포레스트, XGBoost 알고리즘을 훈련하면 단순 분류작업 뺴곤 성능이 낮은 모델만 나온다.

딥러닝은 정형 데이터에도 적용이 되지만 비정형 데이터에서 빛을 발한다. 특히 생성 모델링에선 더욱 더 그렇다.

## 2.2 심층 신경망

여러 은닉 층(hidden layer)을 쌓은 인공 신경망(artificial neural network)이다. 그러므로 딥러닝 = 심층 신경망이라고 봐도 무방하다.

### 2.2.1 신경망이란?

심층 신경망은 층을 연속해서 쌓음, 층은 유닛으로 이루어짐, 유닛은 가중치로 연결됨. 여러 종류의 층이 있다.
널리 사용되는 건 Fully Connected Layer(완전 연결 층 또는 밀집 층), 인접한 모든 층이 연결되면 다층 퍼셉트론(MLP)이라고 함.

<img src="../../images/image-20251221150532883.png" alt="image-20251221150532883" style="zoom:50%;" />

다중 퍼셉트론의 예시, 입력이 출력 레이어 까지 도달할 때 까지 순서대로 변환됨. → 정방향 계산(Forward pass)
각 유닛이 입력의 가중치 합에 비선형 변환 적용하여 다음층에 전달. 정점이 바로 최종 출력 레이어. 하나의 유닛으로 원래 입력이 카테고리에 속활 확률을 출력함.

정확한 예측에 필요한 각 레이어의 가중치 조합을 찾는것이 목표. → 네트워크를 훈련 한다고 함.

훈련 과정에서 이미지의 배치(Batch)가 네트워크에 전달 되고 예측 값을 정답과 비교한다.
100 or 0으로 출력시키는게 목표이지만 웃는 이미지엔 80프로, 안 웃는 얼굴엔 23프로인 식으로 오차가 발생 할 수 있긴 함.

예측 오류는 이 네트워크를 거꾸로 전파해서 예측을 제일 많이 향상시키는 방향으로 가중치를 고쳐나간다. (예시 사진에서 간선을 고친다고 생각하면 편함) 이를 **역전파 (Backpropagation)**라고 한다. 이를 통해 점점 나은 예측을 하게 된다.

### 2.2.2 고수준 특성 학습

신경망의 가장 강력한 속성은 사람이 개입하지 않아도 알아서 입력 데이터에서 특성을 학습하는 능력이다.
우리가 굳이 눈 모양과, 입가의 밝기등을 계산해주지 않아도 되기 때문에 매우 유용하다.
이 오차를 최소화하기 위해 가중치를 어떻게 조절할지 모델이 결정한다.

그림 2-2가 훈련이 완료되었다고 가정하면.

1. 유닛 A는 픽셀의 개별 채널값을 받는다.
    - 이미지 픽셀하나, RGB 채널 하나.
2. 유닛 B는 입력값을 결합해 엣지(edge)와 같은 특정 저수준 특성이 존재할 경우 가장 큰 값을 출력한다.
    - 경계선, 밝기변화, 패턴 등. (여기 선이 있다.)
3. 유닛 C는 저수준 특성을 결합해 이미지에 치아와 같은 고 수준 특성이 보일때 가장 큰 값을 출력한다.
    - 눈, 입, 이빨 등. (이 선들이 이런식으로 모이면 이빨로 보인다.)
4. 유닛 D는 고수준 특성을 결합해 원본 이미지의 사람이 웃을때 제일 큰 값을 출력한다.
    - 웃는다, 안 웃는다. (이빨이 보이고 입 모양을 봤을때 웃고 있다/있지 않다.)

 후속 층의 유닛은 이전 층의 특성을 결합해 원본 입력의 정교한 측면을 표현한다. 이는 학습과정에서 자연스레 일어난다.
각 유닛에 뭘 찾아야 할지, 어떤 수준의 특성을 찾아야 할지 알려줄 필요가 없다.

 입력 층(입력 자체)과 출력 층 사이의 층을 은닉 층이라고 한다. 예제에선 히든 레이어가 두 개밖에 없지만, 실제론 더 많이 있을 수 있다.
많이 쌓을수록 저수준의 특성에서 점진적으로 정보를 구축해 고수준의 특성을 얻을 수 있다.

> 이미지 인식용으로 설계된 ResNet은 152개의 층으로 이루어져 있다.

### 2.2.3 텐서플로우와 케라스

- 구글의 텐서플로우
    - 오픈소스 파이썬 머신러닝 라이브러리이며, 머신러닝 솔루션을 만들 때 널리 사용된다.
    - 텐서 조작에 강점이 있고, 신경망 훈련에 필요한 저수준 기능을 제공한다.
        - 예를 들어 임의의 미분 가능한 표현식의 그레이디언트를 계산하고, 텐서 연산을 효율적으로 실행할 수 있다.
- 케라스
    - 텐서플로우 위에 구축된 고 수준의 API이다. 다양한 신경망 구성요소를 제공하고, 함수형 API로 복잡한 딥러닝 구조를 만들 수 있다.
    - 유연성이 높고 쉽기 떄문에 딥러닝 입문에 사용하기 좋다.

## 2.3 다층 퍼셉트론

지도 학습(Supervised Learning)을 통해 이미지를 분류하는 MLP를 케라스를 통해 쉽게 만들어보자.
판별모델이긴 하지만, 여러 유형의 생성 모델에서 지도 학습이 중요한 역할을 하기 때문에 좋은 주제이다.

### 2.3.1 데이터 준비하기

케라스에서 제공된 6만개의 32x32픽셀 컬러이미지 데이터인 CIFAR-10 데이터셋을 활용. 총 10개의 클래스 중 하나로 분류된다.

<img src="../../images/image-20251221155740252.png" alt="image-20251221155740252" style="zoom:33%;" />

기본적으로 각 픽셀 채널에 대해 0에서 255사이 정수로 구성됨. 
신경망은 각 입력의 절댓값이 1보다 작으면 제일 잘 작동하므로 `/ 255f`를 해줌.
신경망 출력: 이미지가 클래스에 속할 확률 → 이미지 정수 레이블을 one-hot-encoding 된 벡터로 바꿔야 함.

> one-hot encoding을 쉽게 표현한 예시: <img src="../../images/image-20251221162450478.png" alt="image-20251221162450478" style="zoom:33%;" /> 

```python
import numpy as np
from tensorflow.keras import datasets, utils

# 1. CIFAR-10 데이터셋 로드
# x_train: [50000, 32, 32, 3], x_test: [10000, 32, 32, 3]
# y_train: [50000, 10], y_test: [10000, 10]
(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()

NUM_CLASSES = 10

# 2. normalize
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# 3. one-hot encoding
y_train = utils.to_categorical(y_train, NUM_CLASSES)
y_test = utils.to_categorical(y_test, NUM_CLASSES)
```

